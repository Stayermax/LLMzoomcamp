{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516e4f54-8613-4f34-9de6-c81281202fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-03-01-preview'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dlt\n",
    "import yaml\n",
    "import requests\n",
    "from openai import AzureOpenAI\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LLMServiceConfig:\n",
    "    host: str\n",
    "    api_key: str\n",
    "    api_version: str\n",
    "    model: str\n",
    "\n",
    "with open(\"../OPENAI_API_KEY.yaml\") as f:\n",
    "    details = yaml.safe_load(f)[\"Glossary Terms Extraction Service\"]\n",
    "    \n",
    "service_config = LLMServiceConfig(\n",
    "    host=f\"{details['protocol']}://{details['host']}\",\n",
    "    api_key=details['api_key'],\n",
    "    api_version=details['api_version'],\n",
    "    model=details['model']\n",
    ")\n",
    "client = AzureOpenAI(\n",
    "    api_version=service_config.api_version,\n",
    "    azure_endpoint=service_config.host,\n",
    "    api_key=service_config.api_key\n",
    ")\n",
    "model = service_config.model\n",
    "service_config.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1214a28-690c-4164-baa8-0b33b830bfad",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5cf830-5ae9-45e8-8820-648078cf6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "known_weather_data = {\n",
    "    'berlin': 20.0\n",
    "}\n",
    "\n",
    "def get_weather(city: str) -> float:\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d1b3e3-a904-4ff9-9157-77b7b7e53c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"This tool returns temperature for a city. If weather in city is not know, temperature is generated randomly from -5 to 35 degrees Celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of the city you want to know the temperature in\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6c9222-17a5-4834-9507-0de1402fd90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chat_assistant\n",
    "\n",
    "tools = chat_assistant.Tools()\n",
    "tools.add_tool(get_weather, get_weather_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82015a3f-51c9-479f-99f4-84333c6e70cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'get_weather',\n",
       "  'description': 'This tool returns temperature for a city. If weather in city is not know, temperature is generated randomly from -5 to 35 degrees Celsius.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'city': {'type': 'string',\n",
       "     'description': 'Name of the city you want to know the temperature in'}},\n",
       "   'required': ['city'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0733cb85-e35f-4ceb-b18e-7fac82bd154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a weather forecasting assistant. \n",
    "You're given a question about weather in a specific city and you need to answer.\n",
    "\n",
    "Use tools if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb59116-f93c-45bc-902f-49d4c4390036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060c6d9-efec-4704-a374-9b7947c9a8bd",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a871e34-c522-4ad6-acb5-fd86c76344ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weather(city: str, temp: float) -> None:\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68737a35-2faf-4ec2-b928-2ceeb4b6f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"set_weather\",\n",
    "    \"description\": \"This tool set's temperature for a city and stores it permanently\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of the city you want to set the temperature for\"\n",
    "            },\n",
    "            \"temp\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Temperature you want to set\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\", \"temp\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88dc22d1-4505-443e-9326-07d72ce0c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.add_tool(set_weather, set_weather_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb665943-e82f-4f7f-ba95-6c2cfc973803",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a weather forecasting assistant. \n",
    "You're given a question about weather in a specific city and you need to answer.\n",
    "\n",
    "Use tools if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e842878-2a26-49ba-8618-388c7d8cf045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392cb30-8718-4804-a860-12c21eda0ace",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ad10a6-2b6e-4acf-bd73-aa439a2af4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastmcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f5eda9c-0ec2-45cd-8ca4-295e0b440eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastmcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "757c0fab-f3f8-4aa2-9028-c885980e2bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastmcp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b97a71-9d1d-4dd7-9399-3a73a7f33af1",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb6de6b7-a61c-4b30-b9ae-3fd0e71fa401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7680dce8-1929-4a45-91eb-30b60bc3558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/rhfc541d14q5klxp9lqvgx8m0000gq/T/ipykernel_30723/1625779597.py:41: RuntimeWarning: coroutine 'FastMCP.run_async' was never awaited\n",
      "  mcp.run_async()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# weather_server.py\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo 🚀\")\n",
    "\n",
    "@mcp.tool\n",
    "def get_weather(city: str) -> float:\n",
    "    \"\"\"\n",
    "    Retrieves the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to retrieve weather data.\n",
    "\n",
    "    Returns:\n",
    "        float: The temperature associated with the city.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)\n",
    "\n",
    "@mcp.tool\n",
    "def set_weather(city: str, temp: float) -> None:\n",
    "    \"\"\"\n",
    "    Sets the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to set the weather data.\n",
    "        temp (float): The temperature to associate with the city.\n",
    "\n",
    "    Returns:\n",
    "        str: A confirmation string 'OK' indicating successful update.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5b95f-d9f2-4643-b113-a0cfc50a99b1",
   "metadata": {},
   "source": [
    "Response: **'stdio'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f507e635-d6cc-4875-9f54-eada7b31a275",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5dc8642-6b28-4aea-996c-29bc2053cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"get_weather\", \"arguments\": {\"city\":\"berlin\"}}}\n",
    "# {\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"get_weather\", \"arguments\": {\"city\":\"San Francisco\"}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f224f-11ab-4241-a33c-5276b8dc6c09",
   "metadata": {},
   "source": [
    "Response: **{\"jsonrpc\":\"2.0\",\"id\":3,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"20.0\"}],\"structuredContent\":{\"result\":20.0},\"isError\":false}}**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55faf0c-cbd9-406d-a7c2-9c071c47d3e5",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9729f0c6-0265-4224-804f-7ad069679281",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Client(\u001b[33m\"\u001b[39m\u001b[33mmcp_server.py\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m mcp_client:\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mprint\u001b[39m(mcp_client.list_tools())\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m test = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:186\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from fastmcp import Client\n",
    "\n",
    "async def main():\n",
    "    async with Client(\"mcp_server.py\") as mcp_client:\n",
    "        print(await mcp_client.list_tools())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68eec5-9954-49b5-8ad1-161d23e58a70",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8439c49-799a-4423-8656-5998aa8f3324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: python mcp_server.py\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo 🚀', 'version': '1.12.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpankrat/Courses/LLMzoomcamp/venv/lib/python3.11/site-packages/pandas/core/groupby/generic.py:68: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  from pandas.core.frame import DataFrame\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: python mcp_server.py\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo 🚀', 'version': '1.12.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: What's the weatjer in London? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving available tools...\n",
      "Available tools: ['get_weather', 'set_weather']\n",
      "Calling tool 'get_weather' with arguments: {'city': 'London'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"London\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"London\"}', call_id='call_jnRaLl9lCEq07oa5WeqopfRw', name='get_weather', type='function_call', id='fc_687ab5b49b708191aed5c604b104ae28024cd09a8b051bdb', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{\n",
       "  \"content\": [\n",
       "    {\n",
       "      \"type\": \"text\",\n",
       "      \"text\": \"26.9\"\n",
       "    }\n",
       "  ],\n",
       "  \"structuredContent\": {\n",
       "    \"result\": 26.9\n",
       "  },\n",
       "  \"isError\": false\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The current weather in London is 26.9 degrees Celsius. Would you like to know anything else about the weather?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Can you save weather in London?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Could you please specify the temperature you'd like me to save for London?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: The one you told me before\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'set_weather' with arguments: {'city': 'London', 'temp': 26.9}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>set_weather({\"city\":\"London\",\"temp\":26.9})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"London\",\"temp\":26.9}', call_id='call_oiI0msfZzLXqqj4b3WGPJ0Zk', name='set_weather', type='function_call', id='fc_687ab5cda3c48191bf3cf7e9f14417a5024cd09a8b051bdb', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{\n",
       "  \"content\": [\n",
       "    {\n",
       "      \"type\": \"text\",\n",
       "      \"text\": \"OK\"\n",
       "    }\n",
       "  ],\n",
       "  \"isError\": false\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I have saved the weather for London as 26.9 degrees Celsius. Is there anything else you want to do?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: What's the weather in Berlin? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'get_weather' with arguments: {'city': 'Berlin'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"Berlin\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Berlin\"}', call_id='call_sffehGqDPYWLCHhAyI5Dmmkn', name='get_weather', type='function_call', id='fc_687ab5dc45908191a4367068db2ca8ed024cd09a8b051bdb', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{\n",
       "  \"content\": [\n",
       "    {\n",
       "      \"type\": \"text\",\n",
       "      \"text\": \"20.0\"\n",
       "    }\n",
       "  ],\n",
       "  \"structuredContent\": {\n",
       "    \"result\": 20.0\n",
       "  },\n",
       "  \"isError\": false\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The current weather in Berlin is 20.0 degrees Celsius. Would you like me to save this temperature for Berlin as well?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: What's the weather in London? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'get_weather' with arguments: {'city': 'London'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"London\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"London\"}', call_id='call_2rXiCBKnDjwT7ApIw8iO7H5J', name='get_weather', type='function_call', id='fc_687ab5eae1508191afdd0390262c1644024cd09a8b051bdb', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{\n",
       "  \"content\": [\n",
       "    {\n",
       "      \"type\": \"text\",\n",
       "      \"text\": \"26.9\"\n",
       "    }\n",
       "  ],\n",
       "  \"structuredContent\": {\n",
       "    \"result\": 26.9\n",
       "  },\n",
       "  \"isError\": false\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The weather in London is currently 26.9 degrees Celsius. Is there anything else you would like to check?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import advanced_mcp_client as mcp_client\n",
    "import chat_assistant\n",
    "\n",
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"mcp_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()\n",
    "\n",
    "import json\n",
    "\n",
    "import os\n",
    "import dlt\n",
    "import yaml\n",
    "import requests\n",
    "from openai import AzureOpenAI\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LLMServiceConfig:\n",
    "    host: str\n",
    "    api_key: str\n",
    "    api_version: str\n",
    "    model: str\n",
    "\n",
    "\n",
    "with open(\"../OPENAI_API_KEY.yaml\") as f:\n",
    "    details = yaml.safe_load(f)[\"Glossary Terms Extraction Service\"]\n",
    "\n",
    "service_config = LLMServiceConfig(\n",
    "    host=f\"{details['protocol']}://{details['host']}\",\n",
    "    api_key=details['api_key'],\n",
    "    api_version=details['api_version'],\n",
    "    model=details['model']\n",
    ")\n",
    "client = AzureOpenAI(\n",
    "    api_version=service_config.api_version,\n",
    "    azure_endpoint=service_config.host,\n",
    "    api_key=service_config.api_key\n",
    ")\n",
    "model = service_config.model\n",
    "\n",
    "\n",
    "class MCPTools:\n",
    "    def __init__(self, mcp_client):\n",
    "        self.mcp_client = mcp_client\n",
    "        self.tools = None\n",
    "\n",
    "    def get_tools(self):\n",
    "        if self.tools is None:\n",
    "            mcp_tools = self.mcp_client.get_tools()\n",
    "            self.tools = mcp_client.convert_tools_list(mcp_tools)\n",
    "        return self.tools\n",
    "\n",
    "    def function_call(self, tool_call_response):\n",
    "        function_name = tool_call_response.name\n",
    "        arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "        result = self.mcp_client.call_tool(function_name, arguments)\n",
    "\n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call_response.call_id,\n",
    "            \"output\": json.dumps(result, indent=2),\n",
    "        }\n",
    "\n",
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"mcp_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()\n",
    "\n",
    "mcp_tools = mcp_client.MCPTools(mcp_client=our_mcp_client)\n",
    "\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You help users find out the weather in their cities. \n",
    "If they didn't specify a city, ask them. Make sure we always use a city.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=mcp_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d626839-f713-4b6d-9724-476813ead159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMzoomcamp2",
   "language": "python",
   "name": "llmzoomcamp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
